{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment-Analysis-Task.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ae6BrRpnJbc"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,reduce_len=True)\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLogxhKfnWdr"
      },
      "source": [
        "URL = 'https://raw.githubusercontent.com/AliElnafad/Sentiment-Analysis-Task/master/cleaned_dataset%20(1).csv'\n",
        "data  = pd.read_csv(URL)"
      ],
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UkPKnAZMD_i"
      },
      "source": [
        "data.drop(columns='Unnamed: 0' , axis=1 , inplace = True)"
      ],
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rANvy6P_MLmj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "8843f7b5-338b-4296-82eb-16fa2c8e0900"
      },
      "source": [
        "data"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>always wrote series complete stink fest jim be...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>st watched dir steve purcell typical mary kate...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>movie poorly written directed fell asleep minu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>interesting thing miryang secret sunshine acto...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>first read berlin meer expect much thought rig...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>kind picture john lassiter would making today ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>must see saw whipped press screening hilarious...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>nbc ashamed allow child see definitely would t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>movie clumsy mishmash various ghost story susp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>formula movie illegitimate son rich chilenian ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  label\n",
              "0     always wrote series complete stink fest jim be...      0\n",
              "1     st watched dir steve purcell typical mary kate...      0\n",
              "2     movie poorly written directed fell asleep minu...      0\n",
              "3     interesting thing miryang secret sunshine acto...      1\n",
              "4     first read berlin meer expect much thought rig...      0\n",
              "...                                                 ...    ...\n",
              "4995  kind picture john lassiter would making today ...      1\n",
              "4996  must see saw whipped press screening hilarious...      1\n",
              "4997  nbc ashamed allow child see definitely would t...      0\n",
              "4998  movie clumsy mishmash various ghost story susp...      0\n",
              "4999  formula movie illegitimate son rich chilenian ...      0\n",
              "\n",
              "[5000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aqk67z7ODVU7",
        "outputId": "b34f83d7-ab82-4297-eec1-9f3369613058"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dky3ctQarBN_"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'], test_size=0.20, random_state=42)"
      ],
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8wGjHYcrEpu",
        "outputId": "cd0bdff8-6772-4efa-de52-961dfe646f32"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4000,)\n",
            "(1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSuSeWCWr7Dw"
      },
      "source": [
        ""
      ],
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvP1JBKYnsEd"
      },
      "source": [
        "def sigmoid(z): \n",
        "  return 1/( 1 + np.exp(-z))\n",
        "def sigmoid_prime(z):\n",
        "  return sigmoid(z) * (1-sigmoid(z))"
      ],
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_sS8Ua40PaI"
      },
      "source": [
        "def get_freq(data):\n",
        "  posWord =[]\n",
        "  negWord = []\n",
        "  for idx in data.index:\n",
        "    tweet = data.iloc[idx]['text']\n",
        "    if data.iloc[idx]['label'] == 1:\n",
        "      posWord.extend(tokenizer.tokenize(tweet))\n",
        "    else:\n",
        "      negWord.extend(tokenizer.tokenize(tweet))\n",
        "  posCounts = Counter(posWord)\n",
        "  negCounts = Counter(negWord)\n",
        "  posFreq = {}\n",
        "  negFreq = {}\n",
        "  for key , value in posCounts.items():\n",
        "    posFreq[(key,1.0)] = value\n",
        "  for key , value in negCounts.items():\n",
        "    negFreq[(key,0.0)] = value\n",
        "  posFreq.update(negFreq) #all Freq\n",
        "  return posFreq"
      ],
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXR3qszpoO6j"
      },
      "source": [
        "Freqs = get_freq(data)"
      ],
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfSZrpgF4YV5"
      },
      "source": [
        "def extract_features(tweet , Freqs):\n",
        "  words = tokenizer.tokenize(tweet)\n",
        "  X = np.zeros((1,3))\n",
        "  X[0,0] = 1 #bais\n",
        "  for word in words:\n",
        "    X[0,1] += Freqs.get((word , 1.0) , 0)\n",
        "    X[0,2] += Freqs.get((word , 0.0) , 0)\n",
        "    assert(X.shape == (1, 3))\n",
        "  return X"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIKnqzKG02Nx"
      },
      "source": [
        "emp = []\n",
        "for tweet in X_train:\n",
        "  emp.append(extract_features(tweet , Freqs))"
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEUhQTu0y6Vj"
      },
      "source": [
        "train_features = np.array(emp).reshape(len(X_train) , 3)"
      ],
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvzKaT_n8IMN"
      },
      "source": [
        "\n",
        "y_train = np.array(y_train).reshape(len(y_train),1)\n",
        "y_test = np.array(y_test).reshape(len(y_test),1)"
      ],
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99f23YCz8NiD"
      },
      "source": [
        "def gradientDescent(x, y, theta, alpha, num_iters):\n",
        "    '''\n",
        "    Input:\n",
        "        x: matrix of features which is (m,n+1)\n",
        "        y: corresponding labels of the input matrix x, dimensions (m,1)\n",
        "        theta: weight vector of dimension (n+1,1)\n",
        "        alpha: learning rate\n",
        "        num_iters: number of iterations you want to train your model for\n",
        "    Output:\n",
        "        J: the final cost\n",
        "        theta: your final weight vector\n",
        "    Hint: you might want to print the cost to make sure that it is going down.\n",
        "    '''\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    # get 'm', the number of rows in matrix x\n",
        "    m = x.shape[0]     \n",
        "    for i in range(0, num_iters):\n",
        "        \n",
        "        # get z, the dot product of x and theta\n",
        "        z = np.dot(x,theta)\n",
        "        \n",
        "        # get the sigmoid of h\n",
        "        h = sigmoid(z)\n",
        "        \n",
        "        # calculate the cost function\n",
        "        J = -1./m * (np.dot(y.transpose(), np.log(h)) + np.dot((1-y).transpose(),np.log(1-h)))                                                    \n",
        "\n",
        "        # update the weights theta\n",
        "        theta = theta - (alpha/m) * np.dot(x.transpose(),(h-y))\n",
        "        \n",
        "    ### END CODE HERE ###\n",
        "    J = float(J)\n",
        "    return J, theta"
      ],
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krqme-8koMeP"
      },
      "source": [
        "J, theta = gradientDescent(train_features, y_train,np.zeros((3,1)),  1e-9, 1500)"
      ],
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HayoENN_83dW",
        "outputId": "c8d3c21e-93dd-4eef-cbc4-6927a1a3f61d"
      },
      "source": [
        "print(f\"The cost after training is {J:.8f}.\")\n",
        "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
      ],
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The cost after training is 1.19387573.\n",
            "The resulting vector of weights is [5e-08, 0.00053778, -0.00046854]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6TNxnG39Lvn"
      },
      "source": [
        "def predict_tweet(tweet, freqs, theta):\n",
        "    x = extract_features(tweet,freqs)\n",
        "    y_pred = sigmoid(np.dot(x,theta))\n",
        "    return y_pred"
      ],
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhqIWyIh_YMl",
        "outputId": "7bd10447-736f-4c76-ed37-cc54eae61ac2"
      },
      "source": [
        "for tweet in ['I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great']:\n",
        "    print( '%s -> %f' % (tweet, predict_tweet(tweet, Freqs, theta)))"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am happy -> 0.506528\n",
            "I am bad -> 0.375015\n",
            "this movie should have been great. -> 0.510184\n",
            "great -> 0.612389\n",
            "great great -> 0.713967\n",
            "great great great -> 0.797718\n",
            "great great great great -> 0.861697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPLkX4LA_aQJ"
      },
      "source": [
        "def test_logistic_regression(test_x, test_y, freqs, theta):\n",
        "    \n",
        "    # the list for storing predictions\n",
        "    y_hat = []\n",
        "    \n",
        "    for tweet in test_x:\n",
        "        # get the label prediction for the tweet\n",
        "        y_pred = predict_tweet(tweet, freqs, theta)\n",
        "        if y_pred > 0.5:\n",
        "            # append 1.0 to the list\n",
        "            y_hat.append(1)\n",
        "        else:\n",
        "            # append 0 to the list\n",
        "            y_hat.append(0)\n",
        "\n",
        "    # With the above implementation, y_hat is a list, but test_y is (m,1) array\n",
        "    # convert both to one-dimensional arrays in order to compare them using the '==' operator\n",
        "    \n",
        "    accuracy = (y_hat==np.squeeze(test_y)).sum()/len(test_x)\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_mJd94f_iDu",
        "outputId": "4dc18b74-62f9-4968-8bfd-251dfa4f762b"
      },
      "source": [
        "tmp_accuracy = test_logistic_regression(X_test, y_test, Freqs, theta)\n",
        "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic regression model's accuracy = 0.6070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iWYjqvGqwiK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}